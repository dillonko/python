#!/usr/bin/env python
# -*- coding: iso-8859-15 -*-
# generated by wxGlade 0.6.3 on Wed Jul 30 17:48:03 2008
##############################################################################
# This is a very quick and dirty EHakuBot
##############################################################################
# This script will crawl a given website and print the linked domains
##############################################################################
#    EHakuBot is a small quick and dirty script which will crawl a website
#	 and report the linked domains.
#
#    Copyright (C) 2008  Juhapekka Piiroinen
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
#############################################################################
# Contact: juhapekka.piiroinen@gmail.com
# Version: 0.1
#############################################################################
import re,sys,gzip,StringIO,zlib
import urllib2, cookielib
import thread,os
import socket
from urlparse import urlparse
import time,httplib

socket.setdefaulttimeout(10)

global PROCESS_URLS,THREADS_RUNNING
PROCESS_URLS = {}
THREADS_RUNNING = 0

global THREAD_LOCK
THREAD_LOCK = thread.allocate_lock()

global HOSTNAMES
HOSTNAMES = {}

global IPS
IPS = {}

global LAST_DATA 
LAST_DATA = ""

class EHakuBot(object):
	def __init__(self,address):
		self.url = address
		self.re_tags = re.compile(r"</?\w+((\s+\w+(\s*=\s*(?:\".*?\"|'.*?'|[^'\">\s]+))?)+\s*|\s*)/?>")
		#self.re_tags = re.compile(r'{.*}|function.*(.*)|<.*?>')
		self.re_space = re.compile(r'\s+')
		self.re_misc = re.compile(r'var.*?;|&[A-Za-z]*;|&#[0-9]*;|<![\s\S]*?--[ \t\n\r]*>|<script(.*?)>.*?<\/script>|\/\/<!\[CDATA\[.*?\/\/\]\]>')
		self.data = ""

	def Crawl(self):
		global LAST_DATA 
		hname = urlparse(self.url).hostname
		try:
			v = hname +" is " + HOSTNAMES[hname]
		except KeyError:
			try:
				HOSTNAMES[hname] =socket.gethostbyname(hname)
				IPS[HOSTNAMES[hname]] = hname
			except socket.gaierror:
				HOSTNAMES[hname] = hname
				IPS[HOSTNAMES[hname]] = hname
				print "Could not resolve %s. url: %s" % (hname,self.url)
		#self.url = self.url.replace(hname,HOSTNAMES[hname])
		c = cookielib.CookieJar()
		o = urllib2.build_opener(urllib2.HTTPCookieProcessor(c))
		o.addheaders = [('Referer', "http://www.google.co.uk"),
			('Content-Type', 'application/x-www-form-urlencoded'),
			('User-Agent', "EHakuBot 0.1"),
			('Accept-Encoding', "gzip,x-gzip,deflate")]
		try:
			s= o.open(self.url)
			self.data = self.PrepareData(self.Decode(s))
			LAST_DATA = self.data
			s.close()
		except httplib.BadStatusLine:
			print "Received Bad Status Line from %s" % self.url
	def PrepareData(self,data):
		data = data.replace("\r","")
		data = data.replace("\n","")
		data = data.lower()
		return data

	def GetText(self):
		data = self.data
		data = re.findall("<body.*body>",data)[0]
		data = self.re_tags.sub('',data)
		data = self.re_misc.sub(' ',data)
		data = self.re_space.sub(' ',data)
		return data

	def GetLinks(self):
		data = self.data
		data = re.findall("href=\s*\"[^\"]*\"",data)
		retval = []
		for link in data:
			link = link.replace("href=\"","").replace("\"","").strip()
			#print link
			beg = link[:5]
			if beg=="mailt":
				continue
			if beg!="http:":
				beg = link[:2]
				if beg=="//":
					link = "http:" + link
				else:
					beg = link[:1]
					if beg=="/":
						link = self.url + link
					else:
						beg = link[len(link)-1:]
						if beg=="/":
							link = self.url + "/" + link
						else:
							beg = os.path.splitext(link)[1]
							if (beg==".html" or beg==".php" or beg==".jsp" or beg==".htm"):
								link = self.url + "/" + link
							else:
								continue
			#print link
			#print link
			o = urlparse(link)
			try:
				hname = o.hostname
				i = long(hname.replace(".",""))
				link = link.replace(hname,IPS[hname])
				#print link
			except ValueError:
				pass
			retval.append(link)
		return retval

	def Decode(self,s):
		encoding = s.info().get("Content-Encoding")
		if encoding in ('gzip', 'x-gzip', 'deflate'):
			content = s.read()
			if encoding == 'deflate':
				try:
					data = StringIO.StringIO(zlib.decompress(content))
					page = data.read()
				except IOError:
					page = content
			else:
				try:
					data = gzip.GzipFile('', 'rb', 9, StringIO.StringIO(content))
					page = data.read()
				except IOError:
					page = content
					
			
		else:
			page = s.read()
		return page

def ProcessUrl(url):
	global PROCESS_URLS,THREADS_RUNNING
	global HOSTNAMES
	#print "%s" % (url)
	try:
		ehaku = EHakuBot(url)
		ehaku.Crawl()
		#print ehaku.GetText()
		links = ehaku.GetLinks()
		#for link in links:
		#	try:
		#		testValue = PROCESS_URLS[link]
		#		PROCESS_URLS[link] = False
		del ehaku
		return True,links
	except urllib2.HTTPError:
		return False,None
	except urllib2.URLError:
		# yhteydessa vikaa
		#sys.exit(0)
		print "Connection error to %s " % url
		#time.sleep(1.0)
		return False,None
		#return False,None 

def ProcessLinks(links):
	retval = {}
	for link in links:
		hname = urlparse(link).hostname
		retval[hname] = ""
		HOSTNAMES[hname] =socket.gethostbyname(hname)
		IPS[HOSTNAMES[hname]] = hname
		#print hname
	return retval
		
		
def ProcessLevel(links):
	global PROCESS_URLS
	retval = []
	for link in links:
		PROCESS_URLS[link],d = ProcessUrl(link)
		if d:
			retval += d
	return retval
		
print "=============================================="
print "EHakuBot v0.1"
print "=============================================="
LEVEL = 0
(PROCESS_URLS[sys.argv[1]],links) = ProcessUrl(sys.argv[1])
if links:
	data = ProcessLinks(links)
	level1 = len(links)
	print "%s is linked to %s hosts:" % (sys.argv[1],len(data))
	for item in data:
		print "==> " +item + " / " + HOSTNAMES[item]
	#print LAST_DATA
else:
	print "%s doesnt link to anything." % sys.argv[1]
	#print LAST_DATA
